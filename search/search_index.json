{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"#mkdocs","title":"Mkdocs \u8fd8\u633a\u6709\u8da3\u7684\uff01","text":""},{"location":"Cookbooks/Mkdocs/","title":"Mkdocs","text":""},{"location":"Cookbooks/Mkdocs/#installation","title":"Installation","text":"<pre><code>pip install mkdocs\npip install mkdocs-material\npip install https://github.com/mitya57/python-markdown-math/archive/master.zip`\n</code></pre>"},{"location":"Cookbooks/Mkdocs/#create-server-and-publishment","title":"Create, Server and Publishment","text":"<ul> <li> <p>Create a projet: <code>mkdocs new [filename]</code></p> </li> <li> <p>Render to a site: <code>mkdocs serve</code></p> </li> <li> <p>Publish:</p> </li> </ul>"},{"location":"Cookbooks/Mkdocs/#code","title":"Code","text":"<ul> <li>Code Naming, Code Highlighting, Line Numeration: By adding <code>title=\"name\" linenums=\"1\" hl_lines=\"index\"</code> at the right of the first ```, example : </li> </ul> first.py<pre><code>print(\"Hello World\")\n# Yes, it works!\n</code></pre>"},{"location":"Cookbooks/Mkdocs/#template-for-mkdocsyml","title":"Template for mkdocs.yml","text":"<pre><code>site_name: Test # Change here\nnav:\n- Home: 'index.md'\n- 'Cookbooks': - 'Mkdocs': 'Cookbooks/Mkdocs.md'\ntheme: name: material\nfeatures:\n- naviagation.tabs\n- naviagation.sections\n- toc.integrate\n- navigation.top\n- search.suggest\n- search.highlight\n- content.tabs.link\n- content.code.annotation\n- content.code.copy\nlanguage: en\npalette:\n- scheme: default\ntoggle:\nicon: material/toggle-switch-off-outline\nname: Switch to dark mode\nprimary: teal\naccent: purple\n- scheme: slate\ntoggle:\nicon: material/toggle-switch\nname: Switch to light mode\nprimary: teal\naccent: lime\nextra:\nsocial:\n- icon: fontawesome/brands/github-alt\nlink: https://github.com/Languisher # Change to your github link\ncopyright: | # Change based on your own personal information\n&amp;copy; 2023 &lt;a href=\"https://github.com/Languisher\"  target=\"_blank\" rel=\"noopener\"&gt;Brandon Lin&lt;/a&gt;\nextra_javascript: - https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML\nmarkdown_extensions:\n- pymdownx.highlight:\nanchor_linenums: true\n- pymdownx.inlinehilite\n- pymdownx.snippets\n- admonition\n- pymdownx.arithmatex:\ngeneric: true\n- footnotes\n- pymdownx.details\n- pymdownx.superfences\n- pymdownx.mark\n- attr_list\n- mdx_math\n</code></pre> <p>Explications:</p> <ul> <li>The <code>nav</code> configuration setting in your mkdocs.yml file defines which pages are included in the global site navigation menu as well as the structure of that menu. If not provided, the navigation will be automatically created by discovering all the Markdown files in the documentation directory.</li> </ul>"},{"location":"Cookbooks/Mkdocs/#references","title":"References","text":"<ul> <li>Basic Tutorial: https://www.mkdocs.org/user-guide/</li> <li> <p>Material Tutorial: https://www.youtube.com/watch?v=Q-YA_dA8C20</p> </li> <li> <p>Mathjax problem: https://stackoverflow.com/questions/27882261/mkdocs-and-mathjax</p> </li> </ul>"},{"location":"M/AL/Endomorphismes/","title":"Endomorphismes","text":"<p>Exercices : TD</p> <p>Notations :</p> <ul> <li> <p>\\(E\\) est un espace vectoriel euclidien de dimension \\(n\\).</p> </li> <li> <p>\\(\\mathscr E = (e_1,\\cdots, e_n)\\), \\(\\mathscr B=(b_1,\\cdots, b_n)\\) deux bases orthonorm\u00e9es de \\(E\\).</p> </li> <li> <p>\\(P_{\\mathscr B}^{\\mathscr E}\\) le matrice de passage d'une matrice muni d'une base \\(\\mathscr E\\) dans celle d'une base \\(\\mathscr B\\).</p> </li> <li> <p>\\(\\mathscr F=(f_1,\\cdots,f_n)\\) une base quelconque de \\(E\\).</p> </li> <li> <p>\\(\\phi:(x,y) \\mapsto &lt;x,y&gt;\\) le produit scalaire de \\(E\\)</p> </li> <li> <p>\\(\\Phi=\\mathrm{Mat}_\\mathscr{F}(\\phi)= [\\phi(f_i,f_j)]_{(i,j)\\in [\\![1,n]\\!]}\\in \\mathrm{S}_n(\\mathbb R)\\) la matrice de \\(\\phi\\) dans la base \\(\\mathscr F\\).</p> </li> </ul> <p>D\u00e9monstration :   </p>"},{"location":"M/AL/Endomorphismes/#resume","title":"R\u00e9sum\u00e9","text":"<ul> <li> \\[   x\\in E \\iff \\begin{cases}\\mathrm{Mat}_{\\mathscr E}(x) = [&lt;e_i,x&gt;]_i\\in \\mathrm{M}_{m,1}\\\\\\mathrm{Mat}_{\\mathscr{B}}(x) = \\;^tP_{\\mathscr E}^\\mathscr B\\cdot \\mathrm{Mat}_\\mathscr E(x)\\end{cases}   \\] </li> <li> \\[   u \\in \\mathscr{L}(E) \\iff \\begin{cases}\\mathrm{Mat}_\\mathscr E(u) = [&lt;e_i,u(e_j)&gt;]_{(i,j)} \\\\ \\mathrm{Mat}_\\mathscr B(u) = \\;^tP_\\mathscr{E}^{\\mathscr{B}}.\\mathrm{Mat}_\\mathscr{E}(u).P_\\mathscr E^\\mathscr B\\\\ \\boxed{\\mathrm{Mat}_\\mathscr E(u^\\star)=\\;^t\\mathrm{Mat}_\\mathscr E(u)}\\end{cases}   \\] </li> <li> \\[   u \\in \\mathscr S(E) \\iff \\begin{cases} \\;^t\\mathrm{Mat}_\\mathscr E(u) = \\mathrm{Mat}_\\mathscr E(u)\\\\\\mathrm{Mat}_\\mathscr E(u) \\in \\mathrm{S}_n(\\mathbb R)\\end{cases}   \\] </li> <li> \\[   u \\in \\mathscr O(E) \\iff \\begin{cases} \\;^t\\mathrm{Mat}_\\mathscr E(u) =( \\mathrm{Mat}_\\mathscr E(u))^{-1}\\\\\\mathrm{Mat}_\\mathscr E(u) \\in \\mathrm{O}_n(\\mathbb R)\\end{cases}   \\] </li> <li> \\[   u \\in \\mathscr A(E) \\iff \\begin{cases} \\;^t\\mathrm{Mat}_\\mathscr E(u) =- \\mathrm{Mat}_\\mathscr E(u)\\\\\\mathrm{Mat}_\\mathscr E(u) \\in \\mathrm{A}_n(\\mathbb R)\\end{cases}   \\] </li> <li> <p>Si on a le choix de la base dans un espace euclidien, on choisit prequement toujours de travailler en base orthonorm\u00e9e !</p> </li> </ul>"},{"location":"M/AL/Endomorphismes/#decompositions","title":"D\u00e9compositions","text":""},{"location":"M/AL/Endomorphismes/#decomposition-de-cholesky","title":"D\u00e9composition de Cholesky","text":"<ul> <li> <p>Si \\(A \\in \\mathrm{S}_n^{++}(\\mathbb R)\\), il existe une unique matrice \\(T\\in \\mathrm{T}_n^+ \\cap \\mathrm{GL}_n(\\mathbb R)\\) \u00e0 coefficients diagonaux \\(&gt;0\\) tel que :     </p> </li> <li> <p>En ce cas, \\(AX = Y \\iff \\begin{cases} \\;^tT.Z = Y\\\\ T.X = Z\\end{cases}\\)</p> </li> </ul> <p>D\u00e9monstration :</p> <ul> <li> <p>Analyse : L'orthomalisation de Gram-Schimidt appliqu\u00e9 \u00e0 \\(\\mathscr{B}=(b_1, \\cdots, b_n)\\) donne \\(\\mathscr{E} = (e_1,\\cdots, e_n)\\). On trouvera       On sait que \\(u \\in \\mathscr{S}^{++}\\), donc \\(\\exists ! v\\in \\mathscr{S}^{++}\\) tel que \\(u=v \\circ v\\), en m\u00eame temps \\(&lt;c_i,u(c_j) = &lt;v(c_i),v(c_j)&gt;\\)</p> </li> <li> <p>Synth\u00e8se :</p> </li> <li> <p>Existence : \\(T = [&lt;e_i,b_j&gt;]\\), o\u00f9 \\((e_1,\\cdots,e_n)\\) orthonorm\u00e9e de \\((b_1, \\cdots,b_n)\\) bien suffit.</p> </li> <li>Unicit\u00e9 : Si \\(A = \\;^tT_1.T_1 = \\;^tT_2.T_2\\), donc \\(\\Delta=T_1.T_2^{-1} = \\;^tT_1^{-1}.^tT_2\\), appartient respectivement \u00e0 \\(\\mathrm{T}^+\\) et \\(\\mathrm{T}^-\\). Dsonc \\(\\Delta\\) est diagonale. Or, \\(\\(A = \\;^tT_1.T_1 = \\;^tT_2.(^t\\Delta.\\Delta).T_2=\\;^tT_2.T_2\\)\\). Cela implique que \\(\\Delta = \\mathrm{id}_E\\).</li> </ul>"},{"location":"M/AL/Exercices-Endomorphismes/","title":"TD - Endomorphismes","text":""},{"location":"M/AL/Exercices-Endomorphismes/#td-8-e1","title":"TD 8 - E1","text":"<p>On consid\u00e8re      </p> <p>On pose pour \\((f,g)\\in E^2\\),      </p> <ol> <li> <p>Montrer rapidement que \\(E\\) est un espace vectoriel ? Que peut-on dire de sa dimension ?</p> </li> <li> <p>Montrer que \\(\\langle\\,,\\,\\rangle\\) est un produit scalaire sur \\(E\\).</p> </li> <li> <p>On consid\u00e8re les trois fonctions     </p> <p>Montrer que ces trois fonctions sont dans \\(E\\), qu'elles sont ind\u00e9pendantes et calculer le volume du parall\u00e9lipip\u00e8de construite \u00e0 partir de ces trois fonctions.</p> </li> </ol>"},{"location":"M/AL/Exercices-Endomorphismes/#correction","title":"Correction","text":"<ol> <li> <p>On va montrer que \\(E\\) est un sev de \\(\\mathscr C(\\mathbb R^+, \\mathbb R)\\)</p> <ul> <li> <p>La fonction nulle est dans \\(E\\), donc \\(E \\ne \\emptyset\\).</p> </li> <li> <p>Soit \\(\\lambda \\in \\mathbb R\\) et soit \\((f,g)\\in E\\), montrons que \\(\\lambda f+g\\in E\\). Soit \\(t\\in \\mathbb R^+\\).    </p> </li> <li> <p>NB : \\(f(t)g(t)e^{-3t}\\) est int\u00e9grable car \\(fg \\le (f+g)/2\\). </p> </li> <li> <p>Tous les parties sont int\u00e9grable, donc \\(\\lambda f+g \\in E\\).</p> </li> <li> <p>Donc \\(E\\) est un sev de \\(\\mathscr C(\\mathbb R^+, \\mathbb R)\\).</p> </li> </ul> </li> <li> <p>Montrons que \\(\\langle\\,,\\,\\rangle\\) est d\u00e9fini positif, sym\u00e9trique et bilin\u00e9aire.</p> <ul> <li>Soit \\(f\\in E\\), alors      </li> <li> <p>De plus, \\(t \\mapsto f^2(t)e^{-3t}\\) est positive et continue, donc \\(\\langle f,f \\rangle=0 \\implies f=0\\).</p> </li> <li> <p>\\(\\langle\\,f,g\\rangle = \\langle\\,g,f\\rangle\\)</p> </li> <li>\\(\\langle\\,f,\\lambda g+h\\rangle = \\lambda\\langle\\,f,g\\rangle +\\langle\\,f,h\\rangle\\)</li> </ul> </li> <li> <p>Calculerons          en utilisant <code>Python</code> :      <pre><code>def scal(f,g):\nt = sp.Symbol(\"t\")\nreturn sp.integrate(f(t)*g(t)*sp.exp(-3*t), (t, 0, +sp.oo))\nf = [sp.exp, sp.sin, sp.cos]\nGram = sp.zeros(3)\nfor i in range(3):\nfor j in range(3):\nGram[i,j] = scal(f[i], f[j])\nGram\n</code></pre>      Calculerons son d\u00e9terminant :       </p> </li> </ol>"},{"location":"M/AL/Exercices-Endomorphismes/#td8-e2","title":"TD8 - E2","text":"<p>Soit \\(E\\) un espace euclidien, \\(\\mathcal{E}\\) un espace affine de direction \\(E\\) et \\(\\phi\\) une application affine de \\(\\mathcal{E}\\) dans \\(\\mathcal{E}\\) dont l'application lin\u00e9aire sous-jacente sera not\u00e9e \\(\\overrightarrow{\\phi}\\).</p> <p>On pose  </p> <ol> <li> <p>Montrer que si \\(E_1=\\{0_{_E}\\}\\), alors \\(\\phi\\) poss\u00e8de un unique point fixe.</p> </li> <li> <p>On suppose que \\(E_1\\ne\\{0_{_E}\\}\\), montrer que \\(\\phi\\) est alors la compos\u00e9e d'une application affine ayant un point fixe et d'une translation (\u00e9ventuellement nulle).</p> </li> <li> <p>On suppose que   Montrer qu'on peut alors choisir la translation parall\u00e8lement \u00e0 \\(E_1\\).</p> </li> </ol>"},{"location":"ML/CNN/","title":"CNN","text":""},{"location":"ML/CNN/#convolution-operation","title":"Convolution operation","text":"<ul> <li> <p>Convolution operation: To predict the position of a special object \\(x=x(t)\\), we do an average to the measurements in a period of time. However, the more recent the measurement is, the more weight it is given. Therefore, we obtain a smooth estimating function \\(s=s(t)\\):       </p> <ul> <li>\\(w\\) is an effective probability density function, and \\(w(x&lt;0)=0\\).</li> <li>\\(x\\) is the input, \\(w\\) is the kernel function, and \\(f\\) is refered to as feature map.</li> </ul> </li> <li> <p>A discrete version of the operation could be written as:       </p> </li> <li> <p>Convolution operations are commutative, it is because we have flipped the kernel.</p> </li> <li> <p>For a two dimensional figure \\(I\\), using a two-dimensional kernel \\(K\\), the equivalent form is:       </p> </li> <li> <p>However, the cross-correlation is more often used in most nets:      </p> </li> </ul>"},{"location":"ML/CNN/#motivations","title":"Motivations","text":"<ul> <li>Sparse Interactions<ul> <li>The size of the kernel \\(\\ll\\) The size of the input, we use small amount of kernels to detect some small features.</li> </ul> </li> <li>Parameter sharing<ul> <li>Equivariance: \\(f(g(x))=g(f(x))\\), for example translation of certain functions. (Rotations or other operations may not be equivariant)</li> </ul> </li> <li>Pooling function<ul> <li>When the input are slightly translated, the pooling function helps to make the expression of input invariant.</li> <li>We care about it a feature exists, but the position is unimportant.</li> </ul> </li> </ul>"},{"location":"ML/CNN/#variances","title":"Variances","text":"<ul> <li>Multiple convolution processing in the same time: multiple features to be extracted.</li> <li>Input as three dimension, \\((x,y)\\) coordinates and the tunel (RGB).</li> <li>Applying a kernel to a certain input:      <ul> <li>Input: \\(V_{i,j,k}\\), \\(i\\) tunel, position \\((j,k)\\)</li> <li>Kernel: \\(K_{i,j,k,l}\\), \\(i\\) tunel, connection with the \\(j\\) tunel, positioned \\((k,l)\\), </li> <li>Output: Same as input</li> </ul> </li> <li>Note: \\(-1\\) comes from the index problem, modern computer ususally begins its index from 0.</li> </ul>"},{"location":"ML/ML-Basics/","title":"\u6570\u5b66 &amp; \u7406\u8bba\u57fa\u7840","text":""},{"location":"ML/ML-Basics/#linear-regression","title":"Linear Regression \u7ebf\u6027\u56de\u5f52","text":"<ul> <li>\u5b9a\u4e49\u8f93\u51fa\u548c\u5747\u65b9\u8bef\u5dee\u5206\u522b\u4e3a\uff1a\\(\\hat y = w^Tx\\), \\(\\mathrm{MSE} = \\frac{1}{m}\\sum_i(\\hat y - y)_i^2\\)\uff0c\u6211\u4eec\u901a\u8fc7\u6b63\u89c4\u65b9\u7a0b\uff08normal equation\uff09 \u6c42\u5f97\uff1a      </li> </ul>"},{"location":"ML/ML-Basics/#_2","title":"\u6570\u636e\u3001\u5bb9\u91cf","text":"<ul> <li> <p>\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u901a\u8fc7\u6570\u636e\u96c6\u4e0a\u88ab\u79f0\u4e3a\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u7684\u6982\u7387\u5206\u5e03\u751f\u6210\uff0c\u6211\u4eec\u505a\u72ec\u7acb\u540c\u5206\u5e03\u5047\u8bbe\uff08i.i.d. assumption\uff09\uff0c\u4ee5\u4f7f\u968f\u673a\u6a21\u578b\u8bad\u7ec3\u8bef\u5dee\u7684\u671f\u671b\u548c\u8be5\u6a21\u578b\u6d4b\u8bd5\u8bef\u5dee\u7684\u671f\u671b\u4e00\u6837\uff1a</p> <ul> <li>\u6837\u672c\u4e92\u76f8\u72ec\u7acb</li> <li>\u8bad\u7ec3\u96c6\u6d4b\u8bd5\u96c6\u540c\u5206\u5e03</li> </ul> </li> <li></li> </ul>"},{"location":"P/Ondes%20Ondulatoires/","title":"Ondes Ondulatoires","text":""},{"location":"P/Ondes%20Ondulatoires/#interferences-spectrosocopie","title":"Interf\u00e9rences - Spectrosocopie","text":""},{"location":"P/Ondes%20Ondulatoires/#sources-a-spectre-discret","title":"Sources \u00e0 spectre discret","text":"<ul> <li> <p>Une source \u00e0 spectre discret est consid\u00e9r\u00e9e comme la superpostion d'un ensemble discret de sources parfaitement monochromatiques.</p> </li> <li> <p>Une source monochromatique :      </p> </li> <li> <p>Doublet spectral :</p> <p> </p> <p>Preuve :   </p> <ul> <li> <p>Contrast :      </p> <p>Preuve :  </p> </li> </ul> </li> </ul>"},{"location":"P/Ondes%20Ondulatoires/#sources-reelles-a-spectre-continue","title":"Sources r\u00e9elles \u00e0 spectre continue","text":"<ul> <li> <p>La puissance \u00e9mise par la source dans \\([\\omega , \\omega +\\mathrm{d}\\omega]\\), avec \\(\\mathrm d\\omega &gt;0\\) est :           o\u00f9 \\(B_\\omega\\) est appel\u00e9e la densit\u00e9 spectrale de puissance.</p> <ul> <li>La spectrom\u00e9trie est une science \u00e0 d\u00e9terminer \\(B_\\omega\\).</li> </ul> </li> <li> <p>La fonction \\(B_\\omega(\\omega)\\) est nulle partout sauf dans un intervalle de pulsations centr\u00e9 sur une pulsation central \\(\\omega_0\\), on appelle \\(\\Delta \\omega\\) la largeur spectrale du spectre de la source. </p> </li> <li> <p>On peut \u00e9crire :       </p> </li> <li> <p>L'\u00e9clairement global est la somme des \u00e9clairements de chaque intervalle spectral :       </p> <ul> <li>Contrast :     </li> </ul> </li> </ul>"},{"location":"P/Ondes%20Ondulatoires/#diffraction","title":"Diffraction","text":"<ul> <li>Fonction porte et Int\u00e9grale de Fourier :    </li> </ul> <p>D\u00e9monstration :   </p>"},{"location":"P/Ondes%20Ondulatoires/#diffraction-de-frauhofer-pupilles-fondamentales","title":"Diffraction de Frauhofer, Pupilles Fondamentales","text":"<ul> <li> <p>Configuration de Frauhofer : Source \\(S\\) et observateur \\(M\\) sont \u00e0 l'infini. </p> </li> <li> <p>Cas d'une pupille plane en incidence normale :     </p> </li> </ul> <p>D\u00e9monstration :  </p> <ul> <li>L'amplitude diffract\u00e9e dans le cas d'une incidence quelconque :     </li> </ul> <p>D\u00e9monstration :  </p>"}]}